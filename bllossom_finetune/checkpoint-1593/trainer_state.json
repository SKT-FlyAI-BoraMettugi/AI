{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1593,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006277463904582548,
      "grad_norm": 0.932168185710907,
      "learning_rate": 0.00019966520192508892,
      "loss": 2.9256,
      "step": 10
    },
    {
      "epoch": 0.012554927809165096,
      "grad_norm": 0.7231044173240662,
      "learning_rate": 0.0001992467043314501,
      "loss": 1.9155,
      "step": 20
    },
    {
      "epoch": 0.018832391713747645,
      "grad_norm": 0.7482074499130249,
      "learning_rate": 0.00019882820673781127,
      "loss": 1.7249,
      "step": 30
    },
    {
      "epoch": 0.025109855618330193,
      "grad_norm": 0.6125890612602234,
      "learning_rate": 0.00019840970914417242,
      "loss": 1.3715,
      "step": 40
    },
    {
      "epoch": 0.031387319522912745,
      "grad_norm": 0.5538865923881531,
      "learning_rate": 0.00019799121155053358,
      "loss": 1.4044,
      "step": 50
    },
    {
      "epoch": 0.03766478342749529,
      "grad_norm": 0.49625977873802185,
      "learning_rate": 0.00019757271395689477,
      "loss": 1.3989,
      "step": 60
    },
    {
      "epoch": 0.04394224733207784,
      "grad_norm": 0.4827761650085449,
      "learning_rate": 0.00019715421636325593,
      "loss": 1.4428,
      "step": 70
    },
    {
      "epoch": 0.050219711236660386,
      "grad_norm": 0.4940015971660614,
      "learning_rate": 0.0001967357187696171,
      "loss": 1.3618,
      "step": 80
    },
    {
      "epoch": 0.05649717514124294,
      "grad_norm": 0.5945996642112732,
      "learning_rate": 0.00019631722117597825,
      "loss": 1.363,
      "step": 90
    },
    {
      "epoch": 0.06277463904582549,
      "grad_norm": 0.553776741027832,
      "learning_rate": 0.0001958987235823394,
      "loss": 1.4174,
      "step": 100
    },
    {
      "epoch": 0.06905210295040803,
      "grad_norm": 0.5640967488288879,
      "learning_rate": 0.00019548022598870056,
      "loss": 1.3061,
      "step": 110
    },
    {
      "epoch": 0.07532956685499058,
      "grad_norm": 0.5838500261306763,
      "learning_rate": 0.00019506172839506175,
      "loss": 1.2411,
      "step": 120
    },
    {
      "epoch": 0.08160703075957314,
      "grad_norm": 0.4767564833164215,
      "learning_rate": 0.0001946432308014229,
      "loss": 1.2989,
      "step": 130
    },
    {
      "epoch": 0.08788449466415568,
      "grad_norm": 0.5223031044006348,
      "learning_rate": 0.00019422473320778407,
      "loss": 1.342,
      "step": 140
    },
    {
      "epoch": 0.09416195856873823,
      "grad_norm": 0.5819492936134338,
      "learning_rate": 0.00019380623561414523,
      "loss": 1.2332,
      "step": 150
    },
    {
      "epoch": 0.10043942247332077,
      "grad_norm": 0.5224732756614685,
      "learning_rate": 0.00019338773802050639,
      "loss": 1.335,
      "step": 160
    },
    {
      "epoch": 0.10671688637790333,
      "grad_norm": 0.5602819323539734,
      "learning_rate": 0.00019296924042686754,
      "loss": 1.2768,
      "step": 170
    },
    {
      "epoch": 0.11299435028248588,
      "grad_norm": 0.5439789891242981,
      "learning_rate": 0.0001925507428332287,
      "loss": 1.3653,
      "step": 180
    },
    {
      "epoch": 0.11927181418706842,
      "grad_norm": 0.5691562294960022,
      "learning_rate": 0.0001921322452395899,
      "loss": 1.1397,
      "step": 190
    },
    {
      "epoch": 0.12554927809165098,
      "grad_norm": 0.5623987913131714,
      "learning_rate": 0.00019171374764595105,
      "loss": 1.327,
      "step": 200
    },
    {
      "epoch": 0.1318267419962335,
      "grad_norm": 0.4990025758743286,
      "learning_rate": 0.0001912952500523122,
      "loss": 1.2959,
      "step": 210
    },
    {
      "epoch": 0.13810420590081607,
      "grad_norm": 0.5869375467300415,
      "learning_rate": 0.0001908767524586734,
      "loss": 1.3481,
      "step": 220
    },
    {
      "epoch": 0.14438166980539863,
      "grad_norm": 0.7071928977966309,
      "learning_rate": 0.00019045825486503452,
      "loss": 1.3288,
      "step": 230
    },
    {
      "epoch": 0.15065913370998116,
      "grad_norm": 0.5487568974494934,
      "learning_rate": 0.00019003975727139568,
      "loss": 1.3137,
      "step": 240
    },
    {
      "epoch": 0.15693659761456372,
      "grad_norm": 0.5254260897636414,
      "learning_rate": 0.00018962125967775687,
      "loss": 1.2077,
      "step": 250
    },
    {
      "epoch": 0.16321406151914628,
      "grad_norm": 0.6355239748954773,
      "learning_rate": 0.00018920276208411803,
      "loss": 1.3222,
      "step": 260
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 0.6866852045059204,
      "learning_rate": 0.0001887842644904792,
      "loss": 1.2311,
      "step": 270
    },
    {
      "epoch": 0.17576898932831136,
      "grad_norm": 0.5490036010742188,
      "learning_rate": 0.00018836576689684035,
      "loss": 1.1622,
      "step": 280
    },
    {
      "epoch": 0.18204645323289392,
      "grad_norm": 0.606478750705719,
      "learning_rate": 0.00018794726930320153,
      "loss": 1.2302,
      "step": 290
    },
    {
      "epoch": 0.18832391713747645,
      "grad_norm": 0.5532550811767578,
      "learning_rate": 0.0001875287717095627,
      "loss": 1.2107,
      "step": 300
    },
    {
      "epoch": 0.194601381042059,
      "grad_norm": 0.5585848093032837,
      "learning_rate": 0.00018711027411592382,
      "loss": 1.3093,
      "step": 310
    },
    {
      "epoch": 0.20087884494664154,
      "grad_norm": 0.5987712144851685,
      "learning_rate": 0.000186691776522285,
      "loss": 1.2486,
      "step": 320
    },
    {
      "epoch": 0.2071563088512241,
      "grad_norm": 0.5747607946395874,
      "learning_rate": 0.00018627327892864617,
      "loss": 1.1906,
      "step": 330
    },
    {
      "epoch": 0.21343377275580666,
      "grad_norm": 0.5857958793640137,
      "learning_rate": 0.00018585478133500733,
      "loss": 1.3232,
      "step": 340
    },
    {
      "epoch": 0.2197112366603892,
      "grad_norm": 0.6156118512153625,
      "learning_rate": 0.00018543628374136849,
      "loss": 1.3076,
      "step": 350
    },
    {
      "epoch": 0.22598870056497175,
      "grad_norm": 0.529983401298523,
      "learning_rate": 0.00018501778614772967,
      "loss": 1.1786,
      "step": 360
    },
    {
      "epoch": 0.2322661644695543,
      "grad_norm": 0.6434121131896973,
      "learning_rate": 0.00018459928855409083,
      "loss": 1.1651,
      "step": 370
    },
    {
      "epoch": 0.23854362837413684,
      "grad_norm": 0.6037746071815491,
      "learning_rate": 0.000184180790960452,
      "loss": 1.2013,
      "step": 380
    },
    {
      "epoch": 0.2448210922787194,
      "grad_norm": 0.5821081399917603,
      "learning_rate": 0.00018376229336681315,
      "loss": 1.2934,
      "step": 390
    },
    {
      "epoch": 0.25109855618330196,
      "grad_norm": 0.6177308559417725,
      "learning_rate": 0.0001833437957731743,
      "loss": 1.264,
      "step": 400
    },
    {
      "epoch": 0.2573760200878845,
      "grad_norm": 0.6003419756889343,
      "learning_rate": 0.00018292529817953547,
      "loss": 1.2523,
      "step": 410
    },
    {
      "epoch": 0.263653483992467,
      "grad_norm": 0.5575363636016846,
      "learning_rate": 0.00018250680058589665,
      "loss": 1.2351,
      "step": 420
    },
    {
      "epoch": 0.2699309478970496,
      "grad_norm": 0.6556302309036255,
      "learning_rate": 0.0001820883029922578,
      "loss": 1.3164,
      "step": 430
    },
    {
      "epoch": 0.27620841180163214,
      "grad_norm": 0.5866472125053406,
      "learning_rate": 0.00018166980539861897,
      "loss": 1.1167,
      "step": 440
    },
    {
      "epoch": 0.2824858757062147,
      "grad_norm": 0.5813003778457642,
      "learning_rate": 0.00018125130780498013,
      "loss": 1.3218,
      "step": 450
    },
    {
      "epoch": 0.28876333961079725,
      "grad_norm": 0.5293742418289185,
      "learning_rate": 0.0001808328102113413,
      "loss": 1.1309,
      "step": 460
    },
    {
      "epoch": 0.2950408035153798,
      "grad_norm": 0.5999680161476135,
      "learning_rate": 0.00018041431261770245,
      "loss": 1.1407,
      "step": 470
    },
    {
      "epoch": 0.3013182674199623,
      "grad_norm": 0.6984972357749939,
      "learning_rate": 0.0001799958150240636,
      "loss": 1.172,
      "step": 480
    },
    {
      "epoch": 0.3075957313245449,
      "grad_norm": 0.5807093381881714,
      "learning_rate": 0.0001795773174304248,
      "loss": 1.1185,
      "step": 490
    },
    {
      "epoch": 0.31387319522912743,
      "grad_norm": 0.6095670461654663,
      "learning_rate": 0.00017915881983678595,
      "loss": 1.2552,
      "step": 500
    },
    {
      "epoch": 0.32015065913371,
      "grad_norm": 0.6176935434341431,
      "learning_rate": 0.0001787403222431471,
      "loss": 1.1024,
      "step": 510
    },
    {
      "epoch": 0.32642812303829255,
      "grad_norm": 0.6117128133773804,
      "learning_rate": 0.0001783218246495083,
      "loss": 1.1322,
      "step": 520
    },
    {
      "epoch": 0.33270558694287505,
      "grad_norm": 0.5836730003356934,
      "learning_rate": 0.00017790332705586943,
      "loss": 1.1881,
      "step": 530
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 0.6919256448745728,
      "learning_rate": 0.0001774848294622306,
      "loss": 1.1781,
      "step": 540
    },
    {
      "epoch": 0.34526051475204017,
      "grad_norm": 0.6048715710639954,
      "learning_rate": 0.00017706633186859177,
      "loss": 1.2875,
      "step": 550
    },
    {
      "epoch": 0.35153797865662273,
      "grad_norm": 0.6428632736206055,
      "learning_rate": 0.00017664783427495293,
      "loss": 1.1812,
      "step": 560
    },
    {
      "epoch": 0.3578154425612053,
      "grad_norm": 0.5968446135520935,
      "learning_rate": 0.0001762293366813141,
      "loss": 1.0925,
      "step": 570
    },
    {
      "epoch": 0.36409290646578785,
      "grad_norm": 0.6082137823104858,
      "learning_rate": 0.00017581083908767525,
      "loss": 1.1327,
      "step": 580
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 0.658845067024231,
      "learning_rate": 0.00017539234149403644,
      "loss": 1.2199,
      "step": 590
    },
    {
      "epoch": 0.3766478342749529,
      "grad_norm": 0.5680555105209351,
      "learning_rate": 0.00017497384390039757,
      "loss": 1.1641,
      "step": 600
    },
    {
      "epoch": 0.38292529817953547,
      "grad_norm": 0.6168239116668701,
      "learning_rate": 0.00017455534630675873,
      "loss": 1.1907,
      "step": 610
    },
    {
      "epoch": 0.389202762084118,
      "grad_norm": 0.6627384424209595,
      "learning_rate": 0.0001741368487131199,
      "loss": 1.2232,
      "step": 620
    },
    {
      "epoch": 0.3954802259887006,
      "grad_norm": 0.6467877626419067,
      "learning_rate": 0.00017371835111948107,
      "loss": 1.1162,
      "step": 630
    },
    {
      "epoch": 0.4017576898932831,
      "grad_norm": 0.5411285758018494,
      "learning_rate": 0.00017329985352584223,
      "loss": 1.0502,
      "step": 640
    },
    {
      "epoch": 0.40803515379786565,
      "grad_norm": 0.6716124415397644,
      "learning_rate": 0.00017288135593220342,
      "loss": 1.1589,
      "step": 650
    },
    {
      "epoch": 0.4143126177024482,
      "grad_norm": 0.750100314617157,
      "learning_rate": 0.00017246285833856457,
      "loss": 1.1205,
      "step": 660
    },
    {
      "epoch": 0.42059008160703076,
      "grad_norm": 0.6240184307098389,
      "learning_rate": 0.0001720443607449257,
      "loss": 1.1092,
      "step": 670
    },
    {
      "epoch": 0.4268675455116133,
      "grad_norm": 0.7163110971450806,
      "learning_rate": 0.0001716258631512869,
      "loss": 1.2119,
      "step": 680
    },
    {
      "epoch": 0.4331450094161959,
      "grad_norm": 0.6634250283241272,
      "learning_rate": 0.00017120736555764805,
      "loss": 1.1628,
      "step": 690
    },
    {
      "epoch": 0.4394224733207784,
      "grad_norm": 0.5920068621635437,
      "learning_rate": 0.0001707888679640092,
      "loss": 1.181,
      "step": 700
    },
    {
      "epoch": 0.44569993722536094,
      "grad_norm": 0.685039758682251,
      "learning_rate": 0.00017037037037037037,
      "loss": 1.1402,
      "step": 710
    },
    {
      "epoch": 0.4519774011299435,
      "grad_norm": 0.618159294128418,
      "learning_rate": 0.00016995187277673156,
      "loss": 1.1517,
      "step": 720
    },
    {
      "epoch": 0.45825486503452606,
      "grad_norm": 0.6547849774360657,
      "learning_rate": 0.00016953337518309271,
      "loss": 1.112,
      "step": 730
    },
    {
      "epoch": 0.4645323289391086,
      "grad_norm": 0.5844735503196716,
      "learning_rate": 0.00016911487758945387,
      "loss": 1.2382,
      "step": 740
    },
    {
      "epoch": 0.4708097928436911,
      "grad_norm": 0.6468414664268494,
      "learning_rate": 0.00016869637999581503,
      "loss": 1.1144,
      "step": 750
    },
    {
      "epoch": 0.4770872567482737,
      "grad_norm": 0.6308430433273315,
      "learning_rate": 0.0001682778824021762,
      "loss": 1.2069,
      "step": 760
    },
    {
      "epoch": 0.48336472065285624,
      "grad_norm": 0.6815651655197144,
      "learning_rate": 0.00016785938480853735,
      "loss": 1.1049,
      "step": 770
    },
    {
      "epoch": 0.4896421845574388,
      "grad_norm": 0.5753756165504456,
      "learning_rate": 0.00016744088721489854,
      "loss": 1.1135,
      "step": 780
    },
    {
      "epoch": 0.49591964846202136,
      "grad_norm": 0.51607745885849,
      "learning_rate": 0.0001670223896212597,
      "loss": 1.1865,
      "step": 790
    },
    {
      "epoch": 0.5021971123666039,
      "grad_norm": 0.5711470246315002,
      "learning_rate": 0.00016660389202762085,
      "loss": 1.0901,
      "step": 800
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 0.5754309892654419,
      "learning_rate": 0.000166185394433982,
      "loss": 1.1554,
      "step": 810
    },
    {
      "epoch": 0.514752040175769,
      "grad_norm": 0.6652283072471619,
      "learning_rate": 0.00016576689684034317,
      "loss": 1.056,
      "step": 820
    },
    {
      "epoch": 0.5210295040803515,
      "grad_norm": 0.6516441702842712,
      "learning_rate": 0.00016534839924670433,
      "loss": 1.1357,
      "step": 830
    },
    {
      "epoch": 0.527306967984934,
      "grad_norm": 0.670681893825531,
      "learning_rate": 0.0001649299016530655,
      "loss": 1.1091,
      "step": 840
    },
    {
      "epoch": 0.5335844318895167,
      "grad_norm": 0.6143217086791992,
      "learning_rate": 0.00016451140405942668,
      "loss": 1.118,
      "step": 850
    },
    {
      "epoch": 0.5398618957940992,
      "grad_norm": 0.6466380953788757,
      "learning_rate": 0.00016409290646578783,
      "loss": 1.1217,
      "step": 860
    },
    {
      "epoch": 0.5461393596986818,
      "grad_norm": 0.7308236360549927,
      "learning_rate": 0.000163674408872149,
      "loss": 1.1323,
      "step": 870
    },
    {
      "epoch": 0.5524168236032643,
      "grad_norm": 0.6125099658966064,
      "learning_rate": 0.00016325591127851015,
      "loss": 1.1789,
      "step": 880
    },
    {
      "epoch": 0.5586942875078468,
      "grad_norm": 0.676082193851471,
      "learning_rate": 0.0001628374136848713,
      "loss": 1.1329,
      "step": 890
    },
    {
      "epoch": 0.5649717514124294,
      "grad_norm": 0.5871046781539917,
      "learning_rate": 0.00016241891609123247,
      "loss": 1.0751,
      "step": 900
    },
    {
      "epoch": 0.5712492153170119,
      "grad_norm": 0.635615885257721,
      "learning_rate": 0.00016200041849759363,
      "loss": 1.1082,
      "step": 910
    },
    {
      "epoch": 0.5775266792215945,
      "grad_norm": 0.6593565344810486,
      "learning_rate": 0.00016158192090395482,
      "loss": 1.0874,
      "step": 920
    },
    {
      "epoch": 0.583804143126177,
      "grad_norm": 0.6341730356216431,
      "learning_rate": 0.00016116342331031597,
      "loss": 1.0758,
      "step": 930
    },
    {
      "epoch": 0.5900816070307596,
      "grad_norm": 0.6925804615020752,
      "learning_rate": 0.00016074492571667713,
      "loss": 1.2282,
      "step": 940
    },
    {
      "epoch": 0.5963590709353421,
      "grad_norm": 0.6672784686088562,
      "learning_rate": 0.00016032642812303832,
      "loss": 1.0888,
      "step": 950
    },
    {
      "epoch": 0.6026365348399246,
      "grad_norm": 0.6547020673751831,
      "learning_rate": 0.00015990793052939948,
      "loss": 1.0958,
      "step": 960
    },
    {
      "epoch": 0.6089139987445072,
      "grad_norm": 0.6606735587120056,
      "learning_rate": 0.0001594894329357606,
      "loss": 1.2696,
      "step": 970
    },
    {
      "epoch": 0.6151914626490897,
      "grad_norm": 0.6772971749305725,
      "learning_rate": 0.0001590709353421218,
      "loss": 1.118,
      "step": 980
    },
    {
      "epoch": 0.6214689265536724,
      "grad_norm": 0.6363801956176758,
      "learning_rate": 0.00015865243774848295,
      "loss": 1.166,
      "step": 990
    },
    {
      "epoch": 0.6277463904582549,
      "grad_norm": 0.6266388297080994,
      "learning_rate": 0.0001582339401548441,
      "loss": 1.1045,
      "step": 1000
    },
    {
      "epoch": 0.6340238543628374,
      "grad_norm": 0.6218175888061523,
      "learning_rate": 0.00015781544256120527,
      "loss": 1.0408,
      "step": 1010
    },
    {
      "epoch": 0.64030131826742,
      "grad_norm": 0.5792235732078552,
      "learning_rate": 0.00015739694496756646,
      "loss": 1.104,
      "step": 1020
    },
    {
      "epoch": 0.6465787821720025,
      "grad_norm": 0.6294731497764587,
      "learning_rate": 0.00015697844737392762,
      "loss": 1.0829,
      "step": 1030
    },
    {
      "epoch": 0.6528562460765851,
      "grad_norm": 0.7403737902641296,
      "learning_rate": 0.00015655994978028875,
      "loss": 1.1151,
      "step": 1040
    },
    {
      "epoch": 0.6591337099811676,
      "grad_norm": 0.6450133919715881,
      "learning_rate": 0.00015614145218664994,
      "loss": 1.0481,
      "step": 1050
    },
    {
      "epoch": 0.6654111738857501,
      "grad_norm": 0.7045389413833618,
      "learning_rate": 0.0001557229545930111,
      "loss": 1.1781,
      "step": 1060
    },
    {
      "epoch": 0.6716886377903327,
      "grad_norm": 0.6846441626548767,
      "learning_rate": 0.00015530445699937225,
      "loss": 1.1366,
      "step": 1070
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 0.7629581093788147,
      "learning_rate": 0.00015488595940573344,
      "loss": 1.1758,
      "step": 1080
    },
    {
      "epoch": 0.6842435655994978,
      "grad_norm": 0.59344482421875,
      "learning_rate": 0.0001544674618120946,
      "loss": 0.9343,
      "step": 1090
    },
    {
      "epoch": 0.6905210295040803,
      "grad_norm": 0.7283827662467957,
      "learning_rate": 0.00015404896421845576,
      "loss": 1.0856,
      "step": 1100
    },
    {
      "epoch": 0.696798493408663,
      "grad_norm": 0.6444827914237976,
      "learning_rate": 0.00015363046662481692,
      "loss": 1.2752,
      "step": 1110
    },
    {
      "epoch": 0.7030759573132455,
      "grad_norm": 0.6085330843925476,
      "learning_rate": 0.00015321196903117807,
      "loss": 1.2076,
      "step": 1120
    },
    {
      "epoch": 0.709353421217828,
      "grad_norm": 0.6553382277488708,
      "learning_rate": 0.00015279347143753923,
      "loss": 1.0372,
      "step": 1130
    },
    {
      "epoch": 0.7156308851224106,
      "grad_norm": 0.7848677635192871,
      "learning_rate": 0.0001523749738439004,
      "loss": 1.1661,
      "step": 1140
    },
    {
      "epoch": 0.7219083490269931,
      "grad_norm": 0.7708779573440552,
      "learning_rate": 0.00015195647625026158,
      "loss": 1.068,
      "step": 1150
    },
    {
      "epoch": 0.7281858129315757,
      "grad_norm": 0.7204033136367798,
      "learning_rate": 0.00015153797865662274,
      "loss": 1.0772,
      "step": 1160
    },
    {
      "epoch": 0.7344632768361582,
      "grad_norm": 0.7171818017959595,
      "learning_rate": 0.0001511194810629839,
      "loss": 1.0819,
      "step": 1170
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 0.6792163252830505,
      "learning_rate": 0.00015070098346934508,
      "loss": 1.0478,
      "step": 1180
    },
    {
      "epoch": 0.7470182046453233,
      "grad_norm": 0.7011916041374207,
      "learning_rate": 0.00015028248587570621,
      "loss": 1.0659,
      "step": 1190
    },
    {
      "epoch": 0.7532956685499058,
      "grad_norm": 0.771087110042572,
      "learning_rate": 0.00014986398828206737,
      "loss": 1.0572,
      "step": 1200
    },
    {
      "epoch": 0.7595731324544884,
      "grad_norm": 0.7213941216468811,
      "learning_rate": 0.00014944549068842856,
      "loss": 1.1349,
      "step": 1210
    },
    {
      "epoch": 0.7658505963590709,
      "grad_norm": 0.7402423620223999,
      "learning_rate": 0.00014902699309478972,
      "loss": 1.0439,
      "step": 1220
    },
    {
      "epoch": 0.7721280602636534,
      "grad_norm": 0.7291733622550964,
      "learning_rate": 0.00014860849550115088,
      "loss": 0.9946,
      "step": 1230
    },
    {
      "epoch": 0.778405524168236,
      "grad_norm": 0.6595091223716736,
      "learning_rate": 0.00014818999790751204,
      "loss": 1.1717,
      "step": 1240
    },
    {
      "epoch": 0.7846829880728186,
      "grad_norm": 0.7239333987236023,
      "learning_rate": 0.00014777150031387322,
      "loss": 1.1148,
      "step": 1250
    },
    {
      "epoch": 0.7909604519774012,
      "grad_norm": 0.6787055730819702,
      "learning_rate": 0.00014735300272023435,
      "loss": 1.1886,
      "step": 1260
    },
    {
      "epoch": 0.7972379158819837,
      "grad_norm": 0.6657481789588928,
      "learning_rate": 0.0001469345051265955,
      "loss": 1.0916,
      "step": 1270
    },
    {
      "epoch": 0.8035153797865662,
      "grad_norm": 0.6373681426048279,
      "learning_rate": 0.0001465160075329567,
      "loss": 1.0502,
      "step": 1280
    },
    {
      "epoch": 0.8097928436911488,
      "grad_norm": 0.7223085761070251,
      "learning_rate": 0.00014609750993931786,
      "loss": 1.0622,
      "step": 1290
    },
    {
      "epoch": 0.8160703075957313,
      "grad_norm": 0.7469496130943298,
      "learning_rate": 0.00014567901234567902,
      "loss": 1.0787,
      "step": 1300
    },
    {
      "epoch": 0.8223477715003139,
      "grad_norm": 0.7159574627876282,
      "learning_rate": 0.0001452605147520402,
      "loss": 1.1834,
      "step": 1310
    },
    {
      "epoch": 0.8286252354048964,
      "grad_norm": 0.644140362739563,
      "learning_rate": 0.00014484201715840136,
      "loss": 1.0397,
      "step": 1320
    },
    {
      "epoch": 0.834902699309479,
      "grad_norm": 0.7259247899055481,
      "learning_rate": 0.0001444235195647625,
      "loss": 1.1355,
      "step": 1330
    },
    {
      "epoch": 0.8411801632140615,
      "grad_norm": 0.6653093099594116,
      "learning_rate": 0.00014400502197112368,
      "loss": 1.0427,
      "step": 1340
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.7973365187644958,
      "learning_rate": 0.00014358652437748484,
      "loss": 1.1029,
      "step": 1350
    },
    {
      "epoch": 0.8537350910232266,
      "grad_norm": 0.6979200839996338,
      "learning_rate": 0.000143168026783846,
      "loss": 1.1607,
      "step": 1360
    },
    {
      "epoch": 0.8600125549278091,
      "grad_norm": 0.6326670050621033,
      "learning_rate": 0.00014274952919020716,
      "loss": 1.045,
      "step": 1370
    },
    {
      "epoch": 0.8662900188323918,
      "grad_norm": 0.625702440738678,
      "learning_rate": 0.00014233103159656834,
      "loss": 1.0339,
      "step": 1380
    },
    {
      "epoch": 0.8725674827369743,
      "grad_norm": 0.6416098475456238,
      "learning_rate": 0.0001419125340029295,
      "loss": 1.0018,
      "step": 1390
    },
    {
      "epoch": 0.8788449466415568,
      "grad_norm": 0.7704829573631287,
      "learning_rate": 0.00014149403640929063,
      "loss": 1.2115,
      "step": 1400
    },
    {
      "epoch": 0.8851224105461394,
      "grad_norm": 0.7153869271278381,
      "learning_rate": 0.00014107553881565182,
      "loss": 1.0938,
      "step": 1410
    },
    {
      "epoch": 0.8913998744507219,
      "grad_norm": 0.6864328980445862,
      "learning_rate": 0.00014065704122201298,
      "loss": 1.0394,
      "step": 1420
    },
    {
      "epoch": 0.8976773383553045,
      "grad_norm": 0.654288649559021,
      "learning_rate": 0.00014023854362837414,
      "loss": 1.1938,
      "step": 1430
    },
    {
      "epoch": 0.903954802259887,
      "grad_norm": 0.7491419315338135,
      "learning_rate": 0.0001398200460347353,
      "loss": 1.1091,
      "step": 1440
    },
    {
      "epoch": 0.9102322661644695,
      "grad_norm": 0.6868979334831238,
      "learning_rate": 0.00013940154844109648,
      "loss": 0.9598,
      "step": 1450
    },
    {
      "epoch": 0.9165097300690521,
      "grad_norm": 0.6900007724761963,
      "learning_rate": 0.00013898305084745764,
      "loss": 1.0869,
      "step": 1460
    },
    {
      "epoch": 0.9227871939736346,
      "grad_norm": 0.7423304319381714,
      "learning_rate": 0.0001385645532538188,
      "loss": 1.0446,
      "step": 1470
    },
    {
      "epoch": 0.9290646578782172,
      "grad_norm": 0.5945031642913818,
      "learning_rate": 0.00013814605566017996,
      "loss": 1.0632,
      "step": 1480
    },
    {
      "epoch": 0.9353421217827997,
      "grad_norm": 0.7075721621513367,
      "learning_rate": 0.00013772755806654112,
      "loss": 0.9744,
      "step": 1490
    },
    {
      "epoch": 0.9416195856873822,
      "grad_norm": 0.5863187909126282,
      "learning_rate": 0.00013730906047290228,
      "loss": 1.103,
      "step": 1500
    },
    {
      "epoch": 0.9478970495919649,
      "grad_norm": 0.7364603281021118,
      "learning_rate": 0.00013689056287926346,
      "loss": 1.1258,
      "step": 1510
    },
    {
      "epoch": 0.9541745134965474,
      "grad_norm": 0.7016408443450928,
      "learning_rate": 0.00013647206528562462,
      "loss": 1.0274,
      "step": 1520
    },
    {
      "epoch": 0.96045197740113,
      "grad_norm": 0.6275646090507507,
      "learning_rate": 0.00013605356769198578,
      "loss": 1.0329,
      "step": 1530
    },
    {
      "epoch": 0.9667294413057125,
      "grad_norm": 0.6753239631652832,
      "learning_rate": 0.00013563507009834694,
      "loss": 0.9847,
      "step": 1540
    },
    {
      "epoch": 0.9730069052102951,
      "grad_norm": 0.6707074642181396,
      "learning_rate": 0.0001352165725047081,
      "loss": 0.9565,
      "step": 1550
    },
    {
      "epoch": 0.9792843691148776,
      "grad_norm": 0.9146836996078491,
      "learning_rate": 0.00013479807491106926,
      "loss": 1.0973,
      "step": 1560
    },
    {
      "epoch": 0.9855618330194601,
      "grad_norm": 0.659652829170227,
      "learning_rate": 0.00013437957731743042,
      "loss": 0.9848,
      "step": 1570
    },
    {
      "epoch": 0.9918392969240427,
      "grad_norm": 0.7146149277687073,
      "learning_rate": 0.0001339610797237916,
      "loss": 1.0156,
      "step": 1580
    },
    {
      "epoch": 0.9981167608286252,
      "grad_norm": 0.6854270696640015,
      "learning_rate": 0.00013354258213015276,
      "loss": 1.008,
      "step": 1590
    }
  ],
  "logging_steps": 10,
  "max_steps": 4779,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1053234212411802e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
